![Banner](images/banner.png)


## ğŸ§‘â€ğŸ’¼ Jason A. Ballard  
**Instructional Systems Special | Data Scientist | Data and AI Officer | Data Literacy Advocate | Educator in Professional Military Education**

Welcome! I'm Jason A. Ballard, an experienced data and AI integration leader currently serving as a Data and AI Officer for the **US Army Combined Arms Center** at Fort Leavenworth, Kansas. My work bridges data science, AI strategy, and higher education, focusing on transforming decision-making through data literacy and innovation.

I invite you to explore my GitHub repository [jbtallgrass](https://github.com/JBtallgrass?tab=repositories), where I share insights, tools, and resources geared toward data literacy and advanced analytics in educational contexts. My projects emphasize practical solutions, open collaboration, and a commitment to enhancing data accessibility across teams.

### ğŸ”‘ Key Areas of Focus:
- **Data Strategy & Governance**: Developing frameworks that promote data-driven decision-making and cross-departmental data sharing.  
- **AI & Analytics**: Leveraging data analytics and GenAI to unlock insights and drive transformational initiatives within Army University.  
- **Data Literacy & Education**: Equipping leaders and students with data literacy skills critical for today's complex, data-rich environments.  

Please don't hesitate to connect, collaborate, or contact me if our interests align. **Let's make data-driven transformation a reality together.**  

ğŸ“ **LinkedIn**: [Jason A. Ballard](https://www.linkedin.com/in/jasonaballard)

**GitHub** : [jbtallgrass](https://github.com/JBtallgrass)
---
# ğŸŒŠ Rafting Feedback Streaming Project (Module 5)
---
## ğŸ“š Table of Contents  
- [Project Overview](#project-overview)  
- [Technologies Used](#technologies-used)  
- [Setup & Requirements](#setup--requirements)  
- [Project Components](#project-components)  
- [Workflow](#workflow)  
- [Project Structure](#project-structure)  
- [Commands Reference](#commands-reference)  

---

### ğŸ“Œ Project Overview  

This project demonstrates how to build a **streaming analytics pipeline** using **Apache Kafka**, **Python**, and a **relational database (SQLite)** for data storage. It simulates real-time data generation, ingestion, and processing while storing processed data in a structured database for further analysis and integration with BI tools.  

---
# ğŸŒŠ Rafting Feedback Streaming Project

This project is designed to **stream, process, and analyze real-time customer feedback** from rafting trips on the **French Broad River, NC**, using **Apache Kafka**. It integrates customer reviews with **weather and river flow conditions**, providing valuable insights into trip experiences and environmental impacts.

---

### âš ï¸ Note: âš ï¸
The data in this project is **fictitious** with the use of  **Generative AI (GenAI)** assistants to **generate, problem-solve, and debug** the process.

---

### ğŸ¯ Goals  
- **Real-time processing** of structured (CSV) and semi-structured (JSON) data.  
- **Automated enrichment** of feedback with weather and river conditions.  
- **Performance tracking** for rafting guides based on customer reviews.  
- **Predictive insights** into trip satisfaction and environmental impact.  

### ğŸš£ Data Sources  
- **Customer Feedback**: Reviews from rafting trip participants.  
- **Weather Conditions**: Temperature, wind speed, and precipitation.  
- **River Flow Levels**: Water level, current speed, and temperature.  

### âš¡ Technologies Used  
- **Apache Kafka**: Real-time message streaming and processing.  
- **Python**: Data generation, transformation, and analytics.  
- **dotenv**: Environment variable management.  
- **Loguru**: Logging feedback and performance.  
- **matplotlib**: Data visualization for performance trends.  
- **Pandas**: Data manipulation and analysis.  
- **VS Code**: Development environment.  
- **SQLite**: Relational database for storing processed data.  

### ğŸ”‘ Key Features  
- **Real-time data ingestion** from a Kafka topic or a live data file.  
- **Data storage and processing** in SQLite, demonstrating integration with relational databases.  
- **Multiple consumer options**: File-based consumer for testing or Kafka-based consumer for real-time processing.  

---

## ğŸ› ï¸ Setup & Requirements

### âœ… Prerequisites
- **Python 3.11+**
- **Kafka & Zookeeper** installed and running.
    - bin/zookeeper-server-start.sh config/zookeeper.properties
    - bin/kafka-server-start.sh config/server.properties
  - **Virtual Environment** set up for dependency management.

### ğŸ“¥ Installation and Setup

1. Clone the project:
   
2. Create and activate a virtual environment:
   
3. Install dependencies:
  
4. Set up Kafka and Zookeeper:
   Follow the instructions in [Kafka Install Guide](Jballard_docs/kafka-install-guide.md).

5. Configure environment variables in `.env`:
   ```
   ZOOKEEPER_ADDRESS=172.30.179.152:2181
   KAFKA_BROKER_ADDRESS=172.30.179.152:9092
   KAFKA_CONNECTION_TIMEOUT=30000
   RAFTING_TOPIC=rafting_feedback
   RAFTING_INTERVAL_SECONDS=2
   ```
---

## ğŸ”¹ Project Components

### 1. Data Generation
- **Weather Data** (`utils_generate_weather_data.py`): Generates synthetic weather data for the rafting region.
- **River Flow Data** (`utils_generate_river_flow.py`): Creates realistic river flow conditions.
- **Rafting Feedback** (`utils_generate_rafting_data.py`): Produces customer reviews with a mix of positive and negative feedback.

### 2. Kafka Producers and Consumers
- **Rafting Producer (`rafting_producer.py`)**: Streams generated feedback data to the `rafting_feedback` topic.
- **JSON Consumer (`rafting_consumer.py`)**: Logs all feedback, flags negative comments, and enriches messages with weather and river data.
- **CSV Consumer (`csv_rafting_consumer.py`)**: Processes JSON feedback and republishes it as CSV-friendly structured data.
- **CSV Feedback Consumer (`csv_feedback_consumer.py`)**: Writes structured feedback to a CSV file for analysis.
- **Processed CSV Producer (`csv_rafting_producer.py`)**: Enhances and republishes CSV feedback with status flags and trip disruption alerts.

### 3. Visualization
- **Real-Time Feedback Charts (`jb_project_consumer.py`)**:
  - Positive vs. Negative feedback.
  - Weekly performance trends.
  - Weather impact on feedback.
  - River flow and feedback correlation.

---

## ğŸ”„ Workflow

1. **Data Generation**: Run `rafting_producer.py` to generate and stream rafting feedback.
2. **Real-Time Feedback Processing**: Consumers enrich, log, and publish processed feedback.
3. **Visualization**: `jb_project_consumer.py` updates charts every 10 messages.

---

## ğŸ“Š Visualizations

- **Positive vs. Negative Feedback (Bar Chart)** 
- **Weekly Feedback Trends (Line Chart)**
- **Weather vs. Negative Feedback (Bar Chart)**
- **River Flow vs. Feedback Type (Box Plot)**

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/                  # Generated data files
â”œâ”€â”€ images/                # Visualization charts
â”œâ”€â”€ utils/                 # Utility scripts for data generation and logging
â”œâ”€â”€ producers/             # Kafka producers
â”œâ”€â”€ consumers/             # Kafka consumers
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ README.md              # Project documentation
```

## âš ï¸ Important Notes

1. Ensure Kafka and Zookeeper are running before starting producers or consumers.
2. Always verify environment variables in the `.env` file.
3. Regularly check logs in `logs/rafting_project_log.log`.

---

## ğŸ“ License

This project is licensed under the **MIT License**. You are encouraged to fork, modify, and explore the code.

[![Python Version](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/) 

[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)  

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Jason%20A.%20Ballard-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/jasonaballard/)  

---
_Project completed Februray 16th 2025_
---

